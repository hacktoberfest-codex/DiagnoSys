{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1rXAXYMPyL7-yC3SbMpDpQWZeiV3NxX-p","authorship_tag":"ABX9TyN99+jZH4vMEVJW8yxI1IBh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"57j2KgvyAng2","executionInfo":{"status":"ok","timestamp":1684224429349,"user_tz":-330,"elapsed":8396,"user":{"displayName":"Prithwiraj Mohanty","userId":"17672715076520981133"}}},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental import preprocessing\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.applications.vgg19 import preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import PIL.Image as img\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"code","source":["train_dir = 'drive/MyDrive/ML/Covid/Covid19-dataset/train'\n","test_dir = 'drive/MyDrive/ML/Covid/Covid19-dataset/test'"],"metadata":{"id":"JQtgYX7TA8iW","executionInfo":{"status":"ok","timestamp":1684224438943,"user_tz":-330,"elapsed":987,"user":{"displayName":"Prithwiraj Mohanty","userId":"17672715076520981133"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["x_train = []\n","for folder in os.listdir(train_dir):\n","    sub_path = train_dir + '/' + folder\n","    for image in os.listdir(sub_path):\n","        img_path = sub_path + '/' + image\n","        img = cv2.imread(img_path)\n","        img = cv2.resize(img,(224,224)) #VGG19 needs an input of shape 224x224\n","        x_train.append(img)"],"metadata":{"id":"2mJzR0NRBNxn","executionInfo":{"status":"ok","timestamp":1684224552147,"user_tz":-330,"elapsed":111368,"user":{"displayName":"Prithwiraj Mohanty","userId":"17672715076520981133"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["x_test = []\n","for folder in os.listdir(test_dir):\n","    sub_test = test_dir + '/' + folder\n","    for image in os.listdir(sub_test):\n","        img_test = sub_test + '/' + image\n","        imgtest = cv2.imread(img_test)\n","        imgtest = cv2.resize(imgtest,(224,224))\n","        x_test.append(imgtest)"],"metadata":{"id":"uLPMg3PPBUDy","executionInfo":{"status":"ok","timestamp":1684224587337,"user_tz":-330,"elapsed":35214,"user":{"displayName":"Prithwiraj Mohanty","userId":"17672715076520981133"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train = np.array(x_train)/255.0\n","test = np.array(x_test)/255.0"],"metadata":{"id":"myPKGZa8BYhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = ImageDataGenerator(rescale = 1/255.0 , validation_split=0.2)\n","test_data = ImageDataGenerator(rescale = 1/255.0)"],"metadata":{"id":"YimMphHBBhm7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = train_data.flow_from_directory(\n","                    train_dir,\n","                    subset = 'training',\n","                    batch_size=32,\n","                    target_size=(224,224),\n","                    class_mode = 'sparse'\n",")\n","val_set = train_data.flow_from_directory(\n","                    train_dir,\n","                    subset = 'validation',\n","                    batch_size=32,\n","                    target_size=(224,224),\n","                    class_mode = 'sparse'\n",")\n","test_set = test_data.flow_from_directory(\n","                    test_dir,\n","                    batch_size=32,\n","                    target_size=(224,224),\n","                    class_mode = 'sparse'\n",")"],"metadata":{"id":"vb9Nd8A8Blei"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = train_set.classes \n","y_val = val_set.classes\n","y_test = test_set.classes \n","print(train_set.class_indices)"],"metadata":{"id":"rKbk70V9B6ta"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(16,16))\n","for i in range(8):\n","    plt.subplot(2,4,i+1)\n","    plt.imshow(train[i])\n","    plt.title(y_train[i])"],"metadata":{"id":"2ucfSjxTB94v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vgg = VGG19(include_top = False , input_shape = (224,224,3),weights='imagenet')\n","for layer in vgg.layers :\n","    layer.trainable = False"],"metadata":{"id":"vlnCvrXKCBSL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ES = tf.keras.callbacks.EarlyStopping(\n","    patience = 10,\n","    min_delta = 0.001,\n","    verbose = 0\n",")\n","model = tf.keras.Sequential([\n","    layers.RandomFlip(mode='horizontal'),\n","    layers.RandomRotation(factor=0.2),\n","    vgg,\n","    layers.Flatten(),\n","    layers.Dense(3, activation='softmax')\n","])\n","model.compile(\n","    optimizer='adam',\n","    loss = 'sparse_categorical_crossentropy',\n","    metrics = ['accuracy']\n",")"],"metadata":{"id":"_Yt9R39cCOtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training = model.fit_generator(\n","    train_set,\n","    callbacks=[ES],\n","    steps_per_epoch = 7 ,\n","    epochs = 25,\n","    validation_data = val_set\n",")"],"metadata":{"id":"q71HbVuBCTAj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install Keras-Preprocessing"],"metadata":{"id":"BX9r7mZuI6cN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Part 4 - Making a single prediction\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","tf.__version__\n","from keras_preprocessing.image import load_img\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from keras_preprocessing import image\n","\n","\n","def predict_image(imagepath, cnn):\n","    predict = image.load_img(imagepath, target_size = (224, 224))   \n","    predict_modified = image.img_to_array(predict)\n","    predict_modified = predict_modified / 255\n","    predict_modified = np.expand_dims(predict_modified, axis = 0)\n","    result = cnn.predict(predict_modified)\n","    if result[0][0]>= 0.5:\n","        prediction = 'covid'\n","        probability = result[0][0]\n","        print(\"probability = \" + str(probability))\n","    elif result[0][1]>0.5:\n","        prediction = 'Normal'\n","        probability = 1 - result[0][0]\n","        print(\"probability = \" + str(probability))\n","    else:\n","        prediction = 'Viral Pneumonia'\n","        probability = 1 - result[0][0]\n","        print(\"probability = \" + str(probability))\n","    print(\"Prediction = \" + prediction)\n","    return result\n","        \n"],"metadata":{"id":"X_lcwz7OCZdJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filePath=\"drive/MyDrive/ML/Covid/Covid19-dataset/test/Covid/0100.jpeg\"\n","R = predict_image(filePath,model)\n","test_image = image.load_img(\"drive/MyDrive/ML/Covid/Covid19-dataset/test/Covid/0100.jpeg\", target_size = (224, 224))\n","plt.imshow(test_image)\n","R"],"metadata":{"id":"kHOLZ2Q_HwzZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filePath=\"drive/MyDrive/ML/Covid/Covid19-dataset/test/Normal/0105.jpeg\"\n","predict_image(filePath,model)\n","test_image = image.load_img(\"drive/MyDrive/ML/Covid/Covid19-dataset/test/Normal/0105.jpeg\", target_size = (224, 224))\n","plt.imshow(test_image)\n","\n"],"metadata":{"id":"mjL9ZirsH5Mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filePath=\"drive/MyDrive/ML/Covid/Covid19-dataset/test/Viral Pneumonia/0106.jpeg\"\n","predict_image(filePath,model)\n","test_image = image.load_img(\"drive/MyDrive/ML/Covid/Covid19-dataset/test/Viral Pneumonia/0106.jpeg\", target_size = (224, 224))\n","plt.imshow(test_image)\n","\n"],"metadata":{"id":"ruCQKa_JK2NN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"15rf1v3Bgwb3"},"execution_count":null,"outputs":[]}]}